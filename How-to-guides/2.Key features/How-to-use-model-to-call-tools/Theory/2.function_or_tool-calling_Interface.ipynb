{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Which Models Support Tool calling?\n",
    "(same link as last notebook)\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling\n",
    "\n",
    "Tool calling is not universal, but is supported by many popular LLM providers, including Anthropic, Cohere, Google, Mistral, OpenAI, and even for locally-running models via Ollama.\n",
    "\n",
    "LangChain provides a standardized interface for tool calling that is consistent across different models.\n",
    "\n",
    "\n",
    "\n",
    "The standard interface consists of:\n",
    "\n",
    "1) ```ChatModel.bind_tools()```: a method for specifying which tools are available for a model to call. This method accepts LangChain tools as well as Pydantic objects.\n",
    "2) ```AIMessage.tool_calls```: an attribute on the AIMessage returned from the model for accessing the tool calls requested by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatModel.bind_tools()\n",
    "\n",
    "A method for specifying which tools are available for a model to call. This method accepts LangChain tools as well as Pydantic objects.\n",
    "\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/concepts/#tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "Tools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models. Tools are needed whenever you want a model to control parts of your code or call out to external APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does a tool consists of?\n",
    "\n",
    "1. The name of the tool.\n",
    "2. A description of what the tool does.\n",
    "3. A JSON schema defining the inputs to the tool.\n",
    "4. A function (and, optionally, an async variant of the function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is a tool bound to a model?\n",
    "\n",
    "When a tool is bound to a model, the name, description and JSON schema are provided as context to the model. \n",
    "\n",
    "Given a list of tools and a set of instructions, a model can request to call one or more tools with specific inputs. Typical usage may look like the following:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "tools = [...] # Define a list of tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "ai_msg = llm_with_tools.invoke(\"do xyz...\")\n",
    "# -> AIMessage(tool_calls=[ToolCall(...), ...], ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```AIMessage``` returned from the model MAY have ```tool_calls``` associated with it. Read this guide for more information on what the response type may look like.\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/concepts/#aimessage\n",
    "\n",
    "\n",
    "**AIMessage**\n",
    "\n",
    "\n",
    "This represents a message with role \"assistant\". In addition to the content property, these messages also have:\n",
    "\n",
    "**```response_metadata```**\n",
    "\n",
    "The ```response_metadata``` property contains additional metadata about the response. \n",
    "\n",
    "The data here is often specific to each model provider. This is where information like log-probs and token usage may be stored.\n",
    "\n",
    "**```tool_calls```**\n",
    "\n",
    "These represent a decision from an language model to call a tool. They are included as part of an ```AIMessage``` output. They can be accessed from there with the ```.tool_calls``` property.\n",
    "\n",
    "This property returns a list of ```ToolCalls```. A ```ToolCall``` is a **dictionary** with the following arguments:\n",
    "\n",
    "* ```name```: The name of the tool that should be called.\n",
    "* ```args```: The arguments to that tool.\n",
    "* ```id```: The id of that tool call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to invoke the tools and pass back response to the model?\n",
    "\n",
    "Once the chosen tools are invoked, the results can be passed back to the model so that it can complete whatever task it's performing\n",
    "\n",
    "There are generally two different ways to invoke the tool and pass back the response:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1) Invoke with just the arguments\n",
    "\n",
    "### Method-1:\n",
    "\n",
    "When you invoke a tool with just the arguments (```tool_call[\"args\"]```), you will get back the raw **```tool output```** (usually a string). \n",
    "\n",
    "In the example below - the output of invokig the tool is **```tool output```**.\n",
    "\n",
    "You can then create **```tool message```** from it.\n",
    "\n",
    "\n",
    "```python\n",
    "# You will want to previously check that the LLM returned tool calls\n",
    "\n",
    "tool_call = ai_msg.tool_calls[0]\n",
    "# ToolCall(args={...}, id=..., ...)\n",
    "\n",
    "tool_output = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_output,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    name=tool_call[\"name\"]\n",
    ")\n",
    "```\n",
    "\n",
    "Above content field will generally be passed back to the model. \n",
    "\n",
    "\n",
    "### Method-2:\n",
    "\n",
    "If you do not want the raw tool response to be passed to the model, but you still want to keep it around, you can transform the tool output but also pass it as an artifact (read more about ```ToolMessage.artifact```\n",
    "https://python.langchain.com/v0.2/docs/concepts/#toolmessage\n",
    "\n",
    "\n",
    "### ToolMessage\n",
    "This represents a message with role \"tool\", which contains the result of calling a tool. In addition to ```role``` and ```content```, this message has:\n",
    "\n",
    "* a ```tool_call_id``` field which conveys the id of the call to the tool that was called to produce this result.\n",
    "* an ```artifact``` field which can be used to pass along arbitrary artifacts of the tool execution which are useful to track but which should not be sent to the model.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "... # Same code as above\n",
    "response_for_llm = transform(response)\n",
    "tool_message = ToolMessage(\n",
    "    content=response_for_llm,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    name=tool_call[\"name\"],\n",
    "    artifact=tool_output\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke with ToolCall\n",
    "\n",
    "The other way to invoke a tool is to call it with the full ```ToolCall``` that was generated by the model. When you do this, the tool will return a ToolMessage. The benefits of this are that you don't have to write the logic yourself to transform the tool output into a ToolMessage. This generally looks like:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "tool_call = ai_msg.tool_calls[0]\n",
    "# -> ToolCall(args={...}, id=..., ...)\n",
    "tool_message = tool.invoke(tool_call)\n",
    "# -> ToolMessage(\n",
    "    content=\"tool result foobar...\",\n",
    "    tool_call_id=...,\n",
    "    name=\"tool_name\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best practices\n",
    "When designing tools to be used by a model, it is important to keep in mind that:\n",
    "\n",
    "* Chat models that have explicit tool-calling APIs will be better at tool calling than non-fine-tuned models.\n",
    "Tool calling API:\n",
    "https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling\n",
    "\n",
    "* Models will perform better if the tools have well-chosen names, descriptions, and JSON schemas. This another form of prompt engineering.\n",
    "* Simple, narrowly scoped tools are easier for models to use than complex tools.\n",
    "\n",
    "\n",
    "### Tools \"How-to\" guide:\n",
    "https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling\n",
    "\n",
    "\n",
    "### Predefined Tools:\n",
    "https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
