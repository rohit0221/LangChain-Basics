{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "Tools are utilities designed to be called by a model: \n",
    "\n",
    "their inputs are designed to be generated by models, \n",
    "\n",
    "and their outputs are designed to be passed back to models. \n",
    "\n",
    "Tools are needed whenever you want a model to control parts of your code or call out to external APIs.\n",
    "\n",
    "\n",
    "### A tool consists of:\n",
    "\n",
    "1. The name of the tool.\n",
    "2. A description of what the tool does.\n",
    "3. A JSON schema defining the inputs to the tool.\n",
    "4. A function (and, optionally, an async variant of the function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How tools work:\n",
    "\n",
    "When a tool is bound to a model, the **name**, **description** and **JSON schema** are provided as context to the model. \n",
    "\n",
    "Given a list of tools and a set of instructions, a model can request to call one or more tools with specific inputs. \n",
    "Typical usage may look like the following:\n",
    "\n",
    "\n",
    "```\n",
    "tools = [...] # Define a list of tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "ai_msg = llm_with_tools.invoke(\"do xyz...\")\n",
    "# -> AIMessage(tool_calls=[ToolCall(...), ...], ...)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "The AIMessage returned from the model MAY have tool_calls associated with it. Read this guide for more information on what the response type may look like.\n",
    "\n",
    "**tool_calls**\n",
    "\n",
    "These represent a decision from an language model to call a tool. They are included as part of an AIMessage output. They can be accessed from there with the .tool_calls property.\n",
    "\n",
    "This property returns a list of ToolCalls. A ToolCall is a dictionary with the following arguments:\n",
    "\n",
    "- **name**: The name of the tool that should be called.\n",
    "- **args**: The arguments to that tool.\n",
    "- **id**: The id of that tool call.\n",
    "\n",
    "\n",
    "\n",
    "Once the chosen tools are invoked, the results can be passed back to the model so that it can complete whatever task it's performing. There are generally two different ways to invoke the tool and pass back the response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here are generally two different ways to invoke the tool and pass back the response:\n",
    "\n",
    "### 1. Invoke with just the arguments\n",
    "\n",
    "When you invoke a tool with just the arguments, you will get back the raw tool output (usually a string). This generally looks like:\n",
    "\n",
    "```python\n",
    "# You will want to previously check that the LLM returned tool calls\n",
    "tool_call = ai_msg.tool_calls[0]\n",
    "# ToolCall(args={...}, id=..., ...)\n",
    "tool_output = tool.invoke(tool_call[\"args\"])\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_output,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    name=tool_call[\"name\"]\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "Note that the content field will generally be passed back to the model. If you do not want the raw tool response to be passed to the model, but you still want to keep it around, you can transform the tool output but also pass it as an artifact (read more about ToolMessage.artifact here)\n",
    "\n",
    "```python\n",
    "... # Same code as above\n",
    "response_for_llm = transform(response)\n",
    "tool_message = ToolMessage(\n",
    "    content=response_for_llm,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    name=tool_call[\"name\"],\n",
    "    artifact=tool_output\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Invoke with ToolCall\n",
    "The other way to invoke a tool is to call it with the full ToolCall that was generated by the model. \n",
    "\n",
    "When you do this, the tool will return a ToolMessage. \n",
    "\n",
    "The benefits of this are that you don't have to write the logic yourself to transform the tool output into a ToolMessage. This generally looks like:\n",
    "\n",
    "\n",
    "```python\n",
    "tool_call = ai_msg.tool_calls[0]\n",
    "# -> ToolCall(args={...}, id=..., ...)\n",
    "tool_message = tool.invoke(tool_call)\n",
    "# -> ToolMessage(\n",
    "    content=\"tool result foobar...\",\n",
    "    tool_call_id=...,\n",
    "    name=\"tool_name\"\n",
    ")\n",
    "```\n",
    "\n",
    "If you are invoking the tool this way and want to include an artifact for the ToolMessage, you will need to have the tool return two things.\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/how_to/tool_artifacts/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolkits\n",
    "Toolkits are collections of tools that are designed to be used together for specific tasks. They have convenient loading methods.\n",
    "\n",
    "All Toolkits expose a **get_tools** method which returns a list of tools. You can therefore do:\n",
    "\n",
    "```python\n",
    "# Initialize a toolkit\n",
    "toolkit = ExampleTookit(...)\n",
    "\n",
    "# Get list of tools\n",
    "tools = toolkit.get_tools()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prebuilt tools:\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
