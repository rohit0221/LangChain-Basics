{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "import numexpr\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Calculate expression using Python's numexpr library.\n",
    "\n",
    "    Expression should be a single line mathematical expression\n",
    "    that solves the problem.\n",
    "\n",
    "    Examples:\n",
    "        \"37593 * 67\" for \"37593 times 67\"\n",
    "        \"37593**(1/5)\" for \"37593^(1/5)\"\n",
    "    \"\"\"\n",
    "    local_dict = {\"pi\": math.pi, \"e\": math.e}\n",
    "    return str(\n",
    "        numexpr.evaluate(\n",
    "            expression.strip(),\n",
    "            global_dict={},  # restrict access to globals\n",
    "            local_dict=local_dict,  # add common mathematical functions\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "tools = [calculator]\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "\n",
    "\n",
    "class ChainState(TypedDict):\n",
    "    \"\"\"LangGraph state.\"\"\"\n",
    "\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "async def acall_chain(state: ChainState, config: RunnableConfig):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    response = await llm_with_tools.ainvoke(state[\"messages\"], config)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "async def acall_model(state: ChainState, config: RunnableConfig):\n",
    "    response = await llm.ainvoke(state[\"messages\"], config)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(ChainState)\n",
    "graph_builder.add_node(\"call_tool\", acall_chain)\n",
    "graph_builder.add_node(\"execute_tool\", ToolNode(tools))\n",
    "graph_builder.add_node(\"call_model\", acall_model)\n",
    "graph_builder.set_entry_point(\"call_tool\")\n",
    "graph_builder.add_edge(START, \"call_tool\")\n",
    "graph_builder.add_edge(\"call_tool\", \"execute_tool\")\n",
    "graph_builder.add_edge(\"execute_tool\", \"call_model\")\n",
    "graph_builder.add_edge(\"call_model\", END)\n",
    "chain = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize chain:\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(chain.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__start__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mif i have 4563 apples and i get 34567 more apples. then i give someone 678 apple. How many apples will i be left?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Code\\Github\\LangChain-Basics\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1249\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1248\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1251\u001b[0m     config,\n\u001b[0;32m   1252\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   1253\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1254\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[0;32m   1255\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1256\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1257\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1259\u001b[0m ):\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1261\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Code\\Github\\LangChain-Basics\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:740\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ChannelsManager(\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels, checkpoint\n\u001b[0;32m    732\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m channels, get_executor_for_config(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    736\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m managed:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;66;03m# map inputs to channel updates\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_writes \u001b[38;5;241m:=\u001b[39m deque(map_input(input_keys, \u001b[38;5;28minput\u001b[39m)):\n\u001b[0;32m    739\u001b[0m         \u001b[38;5;66;03m# discard any unfinished tasks from previous checkpoint\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m         checkpoint, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_next_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;66;03m# apply input writes\u001b[39;00m\n\u001b[0;32m    750\u001b[0m         _apply_writes(checkpoint, channels, input_writes)\n",
      "File \u001b[1;32mc:\\Code\\Github\\LangChain-Basics\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1472\u001b[0m, in \u001b[0;36m_prepare_next_tasks\u001b[1;34m(checkpoint, processes, channels, managed, config, step, for_execution, manager)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;66;03m# Check if any processes should be run in next step\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;66;03m# If so, prepare the values to be passed to them\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m processes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m-> 1472\u001b[0m     seen \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mversions_seen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;66;03m# If any of the channels read by this process were updated\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m triggers \u001b[38;5;241m:=\u001b[39m [\n\u001b[0;32m   1475\u001b[0m         chan\n\u001b[0;32m   1476\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mtriggers\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If all trigger channels subscribed by this process are not empty\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# then invoke the process with the values of all non-empty channels\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: '__start__'"
     ]
    }
   ],
   "source": [
    "chain.invoke(\"if i have 4563 apples and i get 34567 more apples. then i give someone 678 apple. How many apples will i be left?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__start__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39mexample_query)]}\n\u001b[0;32m      8\u001b[0m events \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mastream(\n\u001b[0;32m      9\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, example_query)]},\n\u001b[0;32m     10\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[0;32m     13\u001b[0m     event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[1;32mc:\\Code\\Github\\LangChain-Basics\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1012\u001b[0m, in \u001b[0;36mPregel.astream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m AsyncChannelsManager(\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels, checkpoint\n\u001b[0;32m   1006\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m channels, AsyncManagedValuesManager(\n\u001b[0;32m   1007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanaged_values_dict, config, \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1008\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m managed:\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;66;03m# map inputs to channel updates\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_writes \u001b[38;5;241m:=\u001b[39m deque(map_input(input_keys, \u001b[38;5;28minput\u001b[39m)):\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;66;03m# discard any unfinished tasks from previous checkpoint\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m         checkpoint, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_next_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m         \u001b[38;5;66;03m# apply input writes\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m         _apply_writes(checkpoint, channels, input_writes)\n",
      "File \u001b[1;32mc:\\Code\\Github\\LangChain-Basics\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1472\u001b[0m, in \u001b[0;36m_prepare_next_tasks\u001b[1;34m(checkpoint, processes, channels, managed, config, step, for_execution, manager)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;66;03m# Check if any processes should be run in next step\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;66;03m# If so, prepare the values to be passed to them\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m processes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m-> 1472\u001b[0m     seen \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mversions_seen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;66;03m# If any of the channels read by this process were updated\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m triggers \u001b[38;5;241m:=\u001b[39m [\n\u001b[0;32m   1475\u001b[0m         chan\n\u001b[0;32m   1476\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mtriggers\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If all trigger channels subscribed by this process are not empty\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# then invoke the process with the values of all non-empty channels\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: '__start__'"
     ]
    }
   ],
   "source": [
    "# Stream chain steps:\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "\n",
    "example_query = \"What is 551368 divided by 82\"\n",
    "\n",
    "initial_state = {\"messages\": [HumanMessage(content=example_query)]}\n",
    "\n",
    "events = chain.astream(\n",
    "    {\"messages\": [(\"user\", example_query)]},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "async for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "import numexpr\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Calculate expression using Python's numexpr library.\n",
    "\n",
    "    Expression should be a single line mathematical expression\n",
    "    that solves the problem.\n",
    "\n",
    "    Examples:\n",
    "        \"37593 * 67\" for \"37593 times 67\"\n",
    "        \"37593**(1/5)\" for \"37593^(1/5)\"\n",
    "    \"\"\"\n",
    "    local_dict = {\"pi\": math.pi, \"e\": math.e}\n",
    "    return str(\n",
    "        numexpr.evaluate(\n",
    "            expression.strip(),\n",
    "            global_dict={},  # restrict access to globals\n",
    "            local_dict=local_dict,  # add common mathematical functions\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "tools = [calculator]\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "\n",
    "\n",
    "class ChainState(TypedDict):\n",
    "    \"\"\"LangGraph state.\"\"\"\n",
    "\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "async def acall_chain(state: ChainState, config: RunnableConfig):\n",
    "    response = await llm_with_tools.ainvoke(state[\"messages\"], config)\n",
    "    return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "\n",
    "async def acall_model(state: ChainState, config: RunnableConfig):\n",
    "    response = await llm.ainvoke(state[\"messages\"], config)\n",
    "    return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(ChainState)\n",
    "graph_builder.add_node(\"call_tool\", acall_chain)\n",
    "graph_builder.add_node(\"execute_tool\", ToolNode(tools))\n",
    "graph_builder.add_node(\"call_model\", acall_model)\n",
    "graph_builder.set_entry_point(\"call_tool\")\n",
    "graph_builder.add_edge(\"call_tool\", \"execute_tool\")\n",
    "graph_builder.add_edge(\"execute_tool\", \"call_model\")\n",
    "graph_builder.add_edge(\"call_model\", END)\n",
    "chain = graph_builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the chain with an example query\n",
    "example_query = \"What is 551368 divided by 82\"\n",
    "\n",
    "# Initializing the input state\n",
    "initial_state = {\"messages\": [HumanMessage(content=example_query)]}\n",
    "\n",
    "# Run the chain asynchronously\n",
    "events = chain.astream(initial_state, stream_mode=\"values\")\n",
    "\n",
    "async for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
