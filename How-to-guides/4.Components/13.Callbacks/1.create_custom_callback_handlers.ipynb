{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create custom callback handlers\n",
    "\n",
    "\n",
    "LangChain has some built-in callback handlers, but you will often want to create your own handlers with custom logic.\n",
    "\n",
    "To create a custom callback handler, we need to determine the ```event(s)``` we want our callback handler to handle as well as what we want our callback handler to do when the event is triggered. \n",
    "\n",
    "Then all we need to do is attach the callback handler to the object, for example via the ```constructor``` or at ```runtime```.\n",
    "\n",
    "\n",
    "## Here is a list of events you can handle:\n",
    "\n",
    "https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain-core-callbacks-base-basecallbackhandler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"My custom handler, token: {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\"Tell me a joke about {animal}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True, callbacks=[MyCustomHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My custom handler, token: \n",
      "My custom handler, token: Why\n",
      "My custom handler, token:  do\n",
      "My custom handler, token:  bears\n",
      "My custom handler, token:  have\n",
      "My custom handler, token:  hairy\n",
      "My custom handler, token:  coats\n",
      "My custom handler, token: ?\n",
      "\n",
      "\n",
      "My custom handler, token: Because\n",
      "My custom handler, token:  they\n",
      "My custom handler, token:  look\n",
      "My custom handler, token:  silly\n",
      "My custom handler, token:  in\n",
      "My custom handler, token:  sweaters\n",
      "My custom handler, token: !\n",
      "My custom handler, token:  üêª\n",
      "My custom handler, token: \n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"animal\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
