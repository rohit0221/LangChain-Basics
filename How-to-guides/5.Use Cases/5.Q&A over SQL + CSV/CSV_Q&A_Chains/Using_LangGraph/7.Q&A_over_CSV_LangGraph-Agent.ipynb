{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.environ.get('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"Q&A_over_CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL\n",
    "\n",
    "You can store the Pandas dataframe in a SQLLiteDB.\n",
    "\n",
    "Using SQL to interact with CSV data is the recommended approach because it is easier to limit permissions and sanitize queries than with arbitrary Python.\n",
    "\n",
    "Most SQL databases make it easy to load a CSV file in as a table (DuckDB, SQLite, etc.). Once you've done this you can use all of the chain and agent-creating techniques outlined in the SQL tutorial. Here's a quick example of how we might do this with SQLite:\n",
    "\n",
    "\n",
    "Once this is done - you can create an SQL agent or apply the chains that we've prepared in folder \"SQL_Q&A_Chain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///titanic.db\")\n",
    "df.to_sql(\"titanic\", engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['titanic']\n",
      "[(79, 1, 2, 'Caldwell, Master. Alden Gates', 'male', 0.83, 0, 2, '248738', 29.0, None, 'S'), (165, 0, 3, 'Panula, Master. Eino Viljami', 'male', 1.0, 4, 1, '3101295', 39.6875, None, 'S'), (173, 1, 3, 'Johnson, Miss. Eleanor Ileen', 'female', 1.0, 1, 1, '347742', 11.1333, None, 'S'), (184, 1, 2, 'Becker, Master. Richard F', 'male', 1.0, 2, 1, '230136', 39.0, 'F4', 'S'), (306, 1, 1, 'Allison, Master. Hudson Trevor', 'male', 0.92, 1, 2, '113781', 151.55, 'C22 C26', 'S'), (382, 1, 3, 'Nakid, Miss. Maria (\"Mary\")', 'female', 1.0, 0, 2, '2653', 15.7417, None, 'C'), (387, 0, 3, 'Goodwin, Master. Sidney Leonard', 'male', 1.0, 5, 2, 'CA 2144', 46.9, None, 'S'), (470, 1, 3, 'Baclini, Miss. Helene Barbara', 'female', 0.75, 2, 1, '2666', 19.2583, None, 'C'), (645, 1, 3, 'Baclini, Miss. Eugenie', 'female', 0.75, 2, 1, '2666', 19.2583, None, 'C'), (756, 1, 2, 'Hamalainen, Master. Viljo', 'male', 0.67, 1, 1, '250649', 14.5, None, 'S'), (789, 1, 3, 'Dean, Master. Bertram Vere', 'male', 1.0, 1, 2, 'C.A. 2315', 20.575, None, 'S'), (804, 1, 3, 'Thomas, Master. Assad Alexander', 'male', 0.42, 0, 1, '2625', 8.5167, None, 'C'), (828, 1, 2, 'Mallet, Master. Andre', 'male', 1.0, 0, 2, 'S.C./PARIS 2079', 37.0042, None, 'C'), (832, 1, 2, 'Richards, Master. George Sibley', 'male', 0.83, 1, 1, '29106', 18.75, None, 'S')]\n"
     ]
    }
   ],
   "source": [
    "db = SQLDatabase(engine=engine)\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "print(db.run(\"SELECT * FROM titanic WHERE Age < 2;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Initialize the agent \n",
    "\n",
    "We'll use the SQLDatabaseToolkit to create a bunch of tools:\n",
    "\n",
    "* Create and execute queries\n",
    "* Check query syntax\n",
    "* Retrieve table descriptions\n",
    "  \n",
    "... and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDataBaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000026E881878E0>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000026E881878E0>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000026E881878E0>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000026E881878E0>, llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000026E93417400>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000026E93438D60>, root_client=<openai.OpenAI object at 0x0000026E88187DC0>, root_async_client=<openai.AsyncOpenAI object at 0x0000026E93417430>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy=''), llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['dialect', 'query'], template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000026E93417400>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000026E93438D60>, root_client=<openai.OpenAI object at 0x0000026E88187DC0>, root_async_client=<openai.AsyncOpenAI object at 0x0000026E93417430>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy='')))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "tools = toolkit.get_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Prompt\n",
    "We will also want to create a system prompt for our agent. This will consist of instructions for how to behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "SQL_PREFIX = \"\"\"You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "You have access to tools for interacting with the database.\n",
    "Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you can query.\n",
    "Do NOT skip this step.\n",
    "Then you should query the schema of the most relevant tables.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(content=SQL_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing agent\n",
    "First, get required package LangGraph\n",
    "\n",
    "\n",
    "We will use a prebuilt LangGraph agent to build our agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neural_ninja\\AppData\\Local\\Temp\\ipykernel_9672\\2704392570.py:4: LangGraphDeprecationWarning: Parameter 'messages_modifier' in function 'create_react_agent' is deprecated as of version 0.1.9 and will be removed in version 0.3.0. Use 'state_modifier' parameter instead.\n",
      "  agent_executor = create_react_agent(llm, tools, messages_modifier=system_message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools, messages_modifier=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_78SA4pkwfizT49jH8OwLQ9tB', 'function': {'arguments': '{}', 'name': 'sql_db_list_tables'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 549, 'total_tokens': 561}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a31de210-9745-458a-9c62-96676f83a4fd-0', tool_calls=[{'name': 'sql_db_list_tables', 'args': {}, 'id': 'call_78SA4pkwfizT49jH8OwLQ9tB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 549, 'output_tokens': 12, 'total_tokens': 561})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='titanic', name='sql_db_list_tables', tool_call_id='call_78SA4pkwfizT49jH8OwLQ9tB')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Uf13dgxoW74Zq6w44LteELCL', 'function': {'arguments': '{\"table_names\":\"titanic\"}', 'name': 'sql_db_schema'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 574, 'total_tokens': 592}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5bd87c427a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2b0f3e85-d2a4-4b29-8c04-3586694acd17-0', tool_calls=[{'name': 'sql_db_schema', 'args': {'table_names': 'titanic'}, 'id': 'call_Uf13dgxoW74Zq6w44LteELCL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 574, 'output_tokens': 18, 'total_tokens': 592})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='\\nCREATE TABLE titanic (\\n\\t\"PassengerId\" BIGINT, \\n\\t\"Survived\" BIGINT, \\n\\t\"Pclass\" BIGINT, \\n\\t\"Name\" TEXT, \\n\\t\"Sex\" TEXT, \\n\\t\"Age\" FLOAT, \\n\\t\"SibSp\" BIGINT, \\n\\t\"Parch\" BIGINT, \\n\\t\"Ticket\" TEXT, \\n\\t\"Fare\" FLOAT, \\n\\t\"Cabin\" TEXT, \\n\\t\"Embarked\" TEXT\\n)\\n\\n/*\\n3 rows from titanic table:\\nPassengerId\\tSurvived\\tPclass\\tName\\tSex\\tAge\\tSibSp\\tParch\\tTicket\\tFare\\tCabin\\tEmbarked\\n1\\t0\\t3\\tBraund, Mr. Owen Harris\\tmale\\t22.0\\t1\\t0\\tA/5 21171\\t7.25\\tNone\\tS\\n2\\t1\\t1\\tCumings, Mrs. John Bradley (Florence Briggs Thayer)\\tfemale\\t38.0\\t1\\t0\\tPC 17599\\t71.2833\\tC85\\tC\\n3\\t1\\t3\\tHeikkinen, Miss. Laina\\tfemale\\t26.0\\t0\\t0\\tSTON/O2. 3101282\\t7.925\\tNone\\tS\\n*/', name='sql_db_schema', tool_call_id='call_Uf13dgxoW74Zq6w44LteELCL')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kEYX3Vktnd08nYRNd1WQ9xfg', 'function': {'arguments': '{\"query\":\"SELECT AVG(Age) as average_age FROM titanic WHERE Survived = 1\"}', 'name': 'sql_db_query_checker'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 861, 'total_tokens': 894}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-abf21367-292f-46ec-bbd7-4e912d5f56c1-0', tool_calls=[{'name': 'sql_db_query_checker', 'args': {'query': 'SELECT AVG(Age) as average_age FROM titanic WHERE Survived = 1'}, 'id': 'call_kEYX3Vktnd08nYRNd1WQ9xfg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 861, 'output_tokens': 33, 'total_tokens': 894})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='```sql\\nSELECT AVG(Age) as average_age FROM titanic WHERE Survived = 1\\n```', name='sql_db_query_checker', tool_call_id='call_kEYX3Vktnd08nYRNd1WQ9xfg')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kGJmnNKXE1LJ8xmshfoGy72I', 'function': {'arguments': '{\"query\":\"SELECT AVG(Age) as average_age FROM titanic WHERE Survived = 1\"}', 'name': 'sql_db_query'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 927, 'total_tokens': 959}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-12f1dada-a51f-417a-99ca-ea54e81b7513-0', tool_calls=[{'name': 'sql_db_query', 'args': {'query': 'SELECT AVG(Age) as average_age FROM titanic WHERE Survived = 1'}, 'id': 'call_kGJmnNKXE1LJ8xmshfoGy72I', 'type': 'tool_call'}], usage_metadata={'input_tokens': 927, 'output_tokens': 32, 'total_tokens': 959})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[(28.343689655172415,)]', name='sql_db_query', tool_call_id='call_kGJmnNKXE1LJ8xmshfoGy72I')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='The average age of survivors is approximately 28.34 years.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 978, 'total_tokens': 992}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-e7c4cb1e-35ee-4d1a-916a-4195970229aa-0', usage_metadata={'input_tokens': 978, 'output_tokens': 14, 'total_tokens': 992})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"what's the average age of survivors?\")]}\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing only the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final_generation(agent_executor,user_input):\n",
    "    last_agent_message = None\n",
    "\n",
    "    # Stream the output from the agent executor\n",
    "    for s in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]}\n",
    "    ):\n",
    "        # Check if the message is from the agent and contains content\n",
    "        if 'agent' in s and 'messages' in s['agent']:\n",
    "            for message in s['agent']['messages']:\n",
    "                if isinstance(message, AIMessage) and message.content:\n",
    "                    last_agent_message = message.content\n",
    "\n",
    "    # Print the last agent message\n",
    "    if last_agent_message:\n",
    "        print(last_agent_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some examples of the correlation between age and fare from the Titanic dataset:\n",
      "\n",
      "1. Age: 0.42 years, Fare: 8.5167\n",
      "2. Age: 0.67 years, Fare: 14.5\n",
      "3. Age: 0.75 years, Fare: 19.2583\n",
      "4. Age: 0.75 years, Fare: 19.2583\n",
      "5. Age: 0.83 years, Fare: 29.0\n",
      "\n",
      "These entries show that as age increases (in years), the fare also tends to increase, though the sample size is very limited. To draw stronger conclusions, a larger dataset would be required to analyze the correlation more effectively.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    print_final_generation(agent_executor,user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
