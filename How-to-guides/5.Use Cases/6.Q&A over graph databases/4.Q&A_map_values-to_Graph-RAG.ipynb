{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to map values to a graph database\n",
    "\n",
    "In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database. When using the built-in graph chains, the LLM is aware of the graph schema, but has no information about the values of properties stored in the database. Therefore, we can introduce a new step in graph database QA system to accurately map values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.environ.get('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"Q&A_over_Graph_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEO4J_URI\"] = os.environ.get('NEO4J_URI')\n",
    "os.environ[\"NEO4J_USERNAME\"] = os.environ.get('NEO4J_USERNAME')\n",
    "os.environ[\"NEO4J_PASSWORD\"] = os.environ.get('NEO4J_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import movie information\n",
    "\n",
    "movies_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM \n",
    "'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv'\n",
    "AS row\n",
    "MERGE (m:Movie {id:row.movieId})\n",
    "SET m.released = date(row.released),\n",
    "    m.title = row.title,\n",
    "    m.imdbRating = toFloat(row.imdbRating)\n",
    "FOREACH (director in split(row.director, '|') | \n",
    "    MERGE (p:Person {name:trim(director)})\n",
    "    MERGE (p)-[:DIRECTED]->(m))\n",
    "FOREACH (actor in split(row.actors, '|') | \n",
    "    MERGE (p:Person {name:trim(actor)})\n",
    "    MERGE (p)-[:ACTED_IN]->(m))\n",
    "FOREACH (genre in split(row.genres, '|') | \n",
    "    MERGE (g:Genre {name:trim(genre)})\n",
    "    MERGE (m)-[:IN_GENRE]->(g))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting entities in the user input\n",
    "\n",
    "We have to extract the types of entities/values we want to map to a graph database. In this example, we are dealing with a movie graph, so we can map movies and people to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person or movies appearing in the text\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting person and movies from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_chain = prompt | llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entities(names=['Casino'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = entity_chain.invoke({\"question\": \"Who played in Casino movie?\"})\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will utilize a simple CONTAINS clause to match entities to database. In practice, you might want to use a fuzzy search or a fulltext index to allow for minor misspellings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_query = \"\"\"MATCH (p:Person|Movie)\n",
    "WHERE p.name CONTAINS $value OR p.title CONTAINS $value\n",
    "RETURN coalesce(p.name, p.title) AS result, labels(p)[0] AS type\n",
    "LIMIT 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_database(entities: Entities) -> Optional[str]:\n",
    "    result = \"\"\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(match_query, {\"value\": entity})\n",
    "        try:\n",
    "            result += f\"{entity} maps to {response[0]['result']} {response[0]['type']} in database\\n\"\n",
    "        except IndexError:\n",
    "            pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Casino maps to Casino Movie in database\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_to_database(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Cypher generating chain\n",
    "We need to define a custom Cypher prompt that takes the entity mapping information along with the schema and the user question to construct a Cypher statement. We will be using the LangChain expression language to accomplish that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Generate Cypher statement based on natural language input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_template = \"\"\"Based on the Neo4j graph schema below, write a Cypher query that would answer the user's question:\n",
    "{schema}\n",
    "Entities in the question map to the following database values:\n",
    "{entities_list}\n",
    "Question: {question}\n",
    "Cypher query:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question, convert it to a Cypher query. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", cypher_template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cypher_response = (\n",
    "    RunnablePassthrough.assign(names=entity_chain)\n",
    "    | RunnablePassthrough.assign(\n",
    "        entities_list=lambda x: map_to_database(x[\"names\"]),\n",
    "        schema=lambda _: graph.get_schema,\n",
    "    )\n",
    "    | cypher_prompt\n",
    "    | llm.bind(stop=[\"\\nCypherResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MATCH (p:Person)-[:ACTED_IN]->(m:Movie {title: 'Casino'})\\nRETURN p.name AS Actor;\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher = cypher_response.invoke({\"question\": \"Who played in Casino movie?\"})\n",
    "cypher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating answers based on database results\n",
    "\n",
    "Now that we have a chain that generates the Cypher statement, we need to execute the Cypher statement against the database and send the database results back to an LLM to generate the final answer. Again, we will be using LCEL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-community\n",
      "Version: 0.0.38\n",
      "Summary: Community contributed LangChain integrations.\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\langchain\\langchain-basics\\venv\\lib\\site-packages\n",
      "Requires: aiohttp, dataclasses-json, langchain-core, langsmith, numpy, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain\n"
     ]
    }
   ],
   "source": [
    "! pip show langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (0.0.38)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (3.10.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Collecting langchain<0.3.0,>=0.2.15 (from langchain-community)\n",
      "  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.37 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (0.2.37)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (0.1.98)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.15->langchain-community)\n",
      "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain<0.3.0,>=0.2.15->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.37->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\langchain\\langchain-basics\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_community-0.2.15-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB 5.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.3 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.3 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.5/2.3 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.3 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.3/1.0 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.0/1.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 5.3 MB/s eta 0:00:00\n",
      "Using cached langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.2\n",
      "    Uninstalling langchain-text-splitters-0.0.2:\n",
      "      Successfully uninstalled langchain-text-splitters-0.0.2\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.20\n",
      "    Uninstalling langchain-0.1.20:\n",
      "      Successfully uninstalled langchain-0.1.20\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.38\n",
      "    Uninstalling langchain-community-0.0.38:\n",
      "      Successfully uninstalled langchain-community-0.0.38\n",
      "Successfully installed langchain-0.2.15 langchain-community-0.2.15 langchain-text-splitters-0.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ionic-langchain 0.2.3 requires langchain<0.2.0,>=0.1.0, but you have langchain 0.2.15 which is incompatible.\n",
      "langchain-experimental 0.0.58 requires langchain<0.2.0,>=0.1.17, but you have langchain 0.2.15 which is incompatible.\n",
      "langchain-experimental 0.0.58 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.2.37 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chains.graph_qa.cypher_utils import CypherQueryCorrector,Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cypher validation tool for relationship directions\n",
    "corrector_schema = [\n",
    "    Schema(el[\"start\"], el[\"type\"], el[\"end\"])\n",
    "    for el in graph.structured_schema.get(\"relationships\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_validation = CypherQueryCorrector(corrector_schema)\n",
    "\n",
    "# Generate natural language response based on database results\n",
    "response_template = \"\"\"Based on the the question, Cypher query, and Cypher response, write a natural language response:\n",
    "Question: {question}\n",
    "Cypher query: {query}\n",
    "Cypher Response: {response}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question and Cypher response, convert it to a natural\"\n",
    "            \" language answer. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", response_template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(query=cypher_response)\n",
    "    | RunnablePassthrough.assign(\n",
    "        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n",
    "    )\n",
    "    | response_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The actors who played in the movie \"Casino\" are Robert De Niro, Joe Pesci, Sharon Stone, and James Woods.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"Who played in Casino movie?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
