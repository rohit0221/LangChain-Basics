{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff: summarize in a single LLM call\n",
    "\n",
    "The chain will take a list of documents, insert them all into a prompt, and pass that prompt to an LLM:\n",
    "\n",
    "\n",
    "\n",
    "We can use ```create_stuff_documents_chain```, especially if using larger context window models such as:\n",
    "\n",
    "* 128k token OpenAI gpt-4o\n",
    "\n",
    "* 200k token Anthropic claude-3-5-sonnet-20240620"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article \"LLM Powered Autonomous Agents\" by Lilian Weng discusses the development and capabilities of agents powered by large language models (LLMs). It outlines a system architecture that includes key components: planning, memory, and tool use. \n",
      "\n",
      "1. **Planning** involves task decomposition, where agents break complex tasks into smaller subgoals and engage in self-reflection to improve performance by learning from previous actions.\n",
      "2. **Memory** differentiates between short-term and long-term memory, with strategies for efficient retrieval of information through maximum inner product search (MIPS) techniques.\n",
      "3. **Tool Use** highlights the importance of integrating external APIs and tools to enhance the capabilities of LLMs, illustrated through various case studies like scientific discovery agents and generative agents in simulations.\n",
      "\n",
      "The article also addresses challenges such as the finite context length of LLMs, difficulties in long-term planning, and the reliability of natural language interfaces. Various proof-of-concept examples like AutoGPT and GPT-Engineer are presented to showcase the practical implementation of these concepts. The discussion concludes with citations and references for further reading on the topic.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",
    ")\n",
    "\n",
    "# Instantiate chain\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Invoke chain\n",
    "result = chain.invoke({\"context\": docs})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming:\n",
    "\n",
    "Note that we can also stream the result token-by-token:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| article| \"|LL|M| Powered| Autonomous| Agents|\"| by| Lil|ian| W|eng| outlines| the| development| and| functionality| of| autonomous| agents| powered| by| large| language| models| (|LL|Ms|).| It| details| the| components| essential| for| such| agents|,| including| planning|,| memory|,| and| tool| use|.| \n",
      "\n",
      "|1|.| **|Agent| System| Overview|**|:| L|LM|s| act| as| the| central| controller| for| autonomous| agents|,| enabling| efficient| planning| through| task| decomposition| and| self|-ref|lection|,| enhancing| decision|-making| capabilities|.\n",
      "\n",
      "|2|.| **|Planning|**|:| This| involves| breaking| down| complex| tasks| into| sub|go|als| and| utilizing| strategies| like| Chain| of| Thought| (|Co|T|)| and| Tree| of| Thoughts| (|To|T|)| for| improved| reasoning| and| task| management|.\n",
      "\n",
      "|3|.| **|Memory|**|:| The| paper| discusses| short|-term| and| long|-term| memory|,| comparing| them| to| human| memory| types|,| and| emphasizes| the| importance| of| Maximum| Inner| Product| Search| (|M|IPS|)| for| efficient| information| retrieval|.\n",
      "\n",
      "|4|.| **|Tool| Use|**|:| L|LM|s| can| leverage| external| tools| and| APIs| to| augment| their| capabilities|,| with| specific| frameworks| like| MR|KL| and| TAL|M| enhancing| their| functional| range|.\n",
      "\n",
      "|5|.| **|Case| Studies|**|:| Examples| include| the| Chem|Crow| agent| for| scientific| discovery| and| Gener|ative| Agents| for| sim|ulating| human|-like| interactions|,| showcasing| the| practical| applications| of| L|LM|-powered| agents|.\n",
      "\n",
      "|6|.| **|Challenges|**|:| The| article| identifies| limitations| such| as| finite| context| lengths|,| difficulties| in| long|-term| planning|,| and| reliability| issues| with| natural| language| interfaces|.\n",
      "\n",
      "|Overall|,| the| piece| presents| a| comprehensive| overview| of| L|LM|-powered| autonomous| agents|,| exploring| their| structure|,| functionality|,| and| potential| applications|,| while| also| addressing| inherent| challenges| and| limitations|.||"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"context\": docs}):\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses the potential and architecture of LLM (Large Language Model) powered autonomous agents. It details three core components essential for their functionality: Planning, Memory, and Tool Use.\n",
      "\n",
      "1. **Planning** involves task decomposition and self-reflection, allowing agents to break down complex tasks into smaller, manageable subgoals and learn from past actions to improve future performance.\n",
      "\n",
      "2. **Memory** is categorized into short-term and long-term memory, with the latter enabling agents to retain and recall information over time. The use of Maximum Inner Product Search (MIPS) facilitates efficient retrieval of this stored information.\n",
      "\n",
      "3. **Tool Use** enhances the agents' capabilities by allowing them to access external APIs for real-time information and processing, effectively bridging the gap between LLMs and the real world.\n",
      "\n",
      "The article also highlights several challenges faced by LLM-powered agents, including limited context lengths, difficulties in long-term planning, and the reliability of natural language interfaces. Several proof-of-concept examples, such as AutoGPT and GPT-Engineer, illustrate the practical implementations of these concepts. The discussion emphasizes the ongoing research and development needed to enhance the robustness and functionality of LLM-powered autonomous agents."
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"context\": docs}):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customise the prompts\n",
    "\n",
    "\n",
    "You can customise the prompt above as required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
