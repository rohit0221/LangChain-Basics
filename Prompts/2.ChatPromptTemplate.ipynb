{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt to chat models/ is a list of chat messages.\n",
    "\n",
    "Each chat message is associated with content, and an additional parameter called role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step-1</span>: Create messages. These are just plain text sentences having {variables} embedded in the them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.schema import SystemMessage,HumanMessage,AIMessage\n",
    "System_Message_Template=\"You are a helpful assistant who is expert in preparing {cusinetype} dishes.\"\n",
    "Human_Message_Template=\"Prepare a dish for me that is {dishtype} and can be prepared within {preptime}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step-2</span>: Create message prompt templates using these messages using \"from_template\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate,AIMessagePromptTemplate\n",
    "System_Prompt_Template=SystemMessagePromptTemplate.from_template(System_Message_Template)\n",
    "Human_Prompt_Template=HumanMessagePromptTemplate.from_template(Human_Message_Template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step-3</span>: Now, use these Prompt Templates to create actual chat prompt Template using \"from_template\". \n",
    "\n",
    "This combined chatprompt will go to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "Chat_Prompt_Template = ChatPromptTemplate.from_messages([System_Prompt_Template,Human_Prompt_Template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\LangChain\\VSCode-Projects\\Langchain-docu3\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat=ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step-4</span>: Create a Chain.\n",
    "\n",
    "This chain uses the ChatPromptTemplate \n",
    "\n",
    "You can define and Output key of this Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "#LLMChain = LLMChain(llm=chat,prompt=Chat_Prompt_Template,output_parser=output_parser)\n",
    "#LLMChain = LLMChain(llm=chat,prompt=Chat_Prompt_Template)\n",
    "\n",
    "llm=chat\n",
    "prompt=Chat_Prompt_Template\n",
    "LLMChain =prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step-5</span>: Invoke the LLMChain by passing the input variables.\n",
    "\n",
    "The final actual ChatPrompt will get created using the ChatPromptTemplate and the input variables that you pass and LLM shall be invoked to generate the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! How about preparing a quick and delicious Vegan Chana Masala? Here's a simple recipe that can be made in under 15 minutes:\\n\\nIngredients:\\n- 1 can of chickpeas, drained and rinsed\\n- 1 small onion, finely chopped\\n- 2 cloves of garlic, minced\\n- 1-inch piece of ginger, grated\\n- 1 small green chili, finely chopped (optional)\\n- 1 can of diced tomatoes\\n- 1 teaspoon ground cumin\\n- 1 teaspoon ground coriander\\n- 1/2 teaspoon turmeric powder\\n- 1/2 teaspoon chili powder\\n- Salt to taste\\n- Fresh cilantro leaves for garnish\\n- 1 tablespoon oil\\n\\nInstructions:\\n1. Heat oil in a pan over medium heat. Add the chopped onions and sauté until they turn translucent.\\n2. Add the minced garlic, grated ginger, and chopped green chili. Sauté for another minute until fragrant.\\n3. Add the ground cumin, coriander, turmeric, and chili powder. Stir well to combine the spices with the onion mixture.\\n4. Add the diced tomatoes and cook for a few minutes until the tomatoes break down and the mixture thickens slightly.\\n5. Add the drained chickpeas to the pan and stir well to coat them with the tomato and spice mixture.\\n6. Add salt to taste and simmer the chana masala for about 5-7 minutes, allowing the flavors to meld together.\\n7. Garnish with fresh cilantro leaves before serving.\\n\\nYou can serve this Vegan Chana Masala with steamed rice, quinoa, or flatbread for a complete and satisfying meal. Enjoy!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLMChain.invoke({\"cusinetype\":\"indian\",\"dishtype\":\"vegan\",\"preptime\":\"15 minutes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
